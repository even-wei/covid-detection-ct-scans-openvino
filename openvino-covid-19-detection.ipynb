{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351ac1a2",
   "metadata": {},
   "source": [
    "# COVID-19 Detection on CT Scans\n",
    "\n",
    "In this notebook, we will optimize a pre-trained models for COVID-19 detection and inferece using OpenVINO.\n",
    "\n",
    "The dataset and models are from https://github.com/kaushikjadhav01/COVID-19-Detection-Flask-App-based-on-Chest-X-rays-and-CT-Scans/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e87eb",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98492c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mo_tf\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2459cd3",
   "metadata": {},
   "source": [
    "## 2. Download dataset and models\n",
    "Download and unzip file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1f82fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-27 08:36:25--  https://docs.google.com/uc?export=download&confirm=b94J&id=1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq\n",
      "Resolving docs.google.com (docs.google.com)... 108.177.125.138, 108.177.125.139, 108.177.125.100, ...\n",
      "Connecting to docs.google.com (docs.google.com)|108.177.125.138|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e=download [following]\n",
      "--2021-08-27 08:36:26--  https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e=download\n",
      "Resolving doc-10-bc-docs.googleusercontent.com (doc-10-bc-docs.googleusercontent.com)... 142.250.157.132, 2404:6800:4008:c13::84\n",
      "Connecting to doc-10-bc-docs.googleusercontent.com (doc-10-bc-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://docs.google.com/nonceSigner?nonce=vu0o2fcq1e3ns&continue=https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e%3Ddownload&hash=340fgmqo8drdceqe6gh08iu916qvp95g [following]\n",
      "--2021-08-27 08:36:26--  https://docs.google.com/nonceSigner?nonce=vu0o2fcq1e3ns&continue=https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e%3Ddownload&hash=340fgmqo8drdceqe6gh08iu916qvp95g\n",
      "Connecting to docs.google.com (docs.google.com)|108.177.125.138|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e=download&nonce=vu0o2fcq1e3ns&user=03907061901375805182Z&hash=i81mj18o79qpuqqcfndp2dv9v2ci33cq [following]\n",
      "--2021-08-27 08:36:27--  https://doc-10-bc-docs.googleusercontent.com/docs/securesc/3p0p6r406b6q3d57vhjp9c2638pakn7l/9odfdgkgmdp5p8886akk7eoh6hm9nne9/1630053375000/00998131069543110034/03907061901375805182Z/1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq?e=download&nonce=vu0o2fcq1e3ns&user=03907061901375805182Z&hash=i81mj18o79qpuqqcfndp2dv9v2ci33cq\n",
      "Connecting to doc-10-bc-docs.googleusercontent.com (doc-10-bc-docs.googleusercontent.com)|142.250.157.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-zip-compressed]\n",
      "Saving to: ‘data_and_models.zip’\n",
      "\n",
      "data_and_models.zip     [ <=>                ] 925.03M   122MB/s    in 7.1s    \n",
      "\n",
      "2021-08-27 08:36:34 (130 MB/s) - ‘data_and_models.zip’ saved [969964066]\n",
      "\n",
      "Dataset and models are ready.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data_and_models'):\n",
    "    !(wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1dA-rdmDmCGa3xxW5KpfLJdo7M54lPcQq\" -O data_and_models.zip && rm -rf /tmp/cookies.txt)\n",
    "    with zipfile.ZipFile('data_and_models.zip', 'r') as zf:\n",
    "        zf.extractall()\n",
    "    os.rename('data and models', 'data_and_models')\n",
    "    !(rm data_and_models.zip)\n",
    "print('Dataset and models are ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079c683",
   "metadata": {},
   "source": [
    "## 3. Optimize Model\n",
    "OpenVINO model optimizer does not support Keras H5 models. We need to convert Keras H5 models into TensorFlow SavedModel.\n",
    "\n",
    "Select the model you want to convert, here we use `resnet_chest`.\n",
    "Model names:\n",
    "- inceptionv3_chest\n",
    "- resnet_chest\n",
    "- vgg_chest\n",
    "- xception_chest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f25708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: resnet_chest/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# model_name = 'inceptionv3_chest'\n",
    "model_name = 'resnet_chest'\n",
    "# model_name = 'vgg_chest'\n",
    "# model_name = 'xception_chest'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    model_h5 = tf.keras.models.load_model(f'data_and_models/models/{model_name}.h5')\n",
    "    tf.saved_model.save(model_h5, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec964f",
   "metadata": {},
   "source": [
    "#### Prepare commnad for optimizing the model\n",
    "Construct the command for model optimizer. We save the converted model in the directory named after selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd47aa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert TensorFlow to OpenVINO:\n",
      "\"/opt/conda/bin/python\" \"/opt/conda/lib/python3.7/site-packages/mo_tf.py\" --saved_model_dir \"resnet_chest\" --input_shape \"[1,224,224,3]\" --data_type FP32 --output_dir \"resnet_chest\"\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the Model Optimizer script\n",
    "mo_path = str(Path(mo_tf.__file__))\n",
    "ir_path = Path(os.path.join(model_name, 'saved_model.xml'))\n",
    "\n",
    "mo_command = f'''\"{sys.executable}\"\n",
    "                 \"{mo_path}\" \n",
    "                 --saved_model_dir \"{model_name}\" \n",
    "                 --input_shape \"[1,224,224,3]\"\n",
    "                 --data_type FP32\n",
    "                 --output_dir \"{model_name}\" \n",
    "                 '''\n",
    "mo_command = ' '.join(mo_command.split())\n",
    "print('Model Optimizer command to convert TensorFlow to OpenVINO:')\n",
    "print(mo_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b8efb",
   "metadata": {},
   "source": [
    "#### Run Model Optimizer if the IR model file does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting TensorFlow model to IR... This may take a few minutes.\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \t/home/jovyan/resnet_chest\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,224,224,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "\t- Inference Engine found in: \t/opt/conda/lib/python3.7/site-packages/openvino\n",
      "Inference Engine version: \t2.1.2021.3.0-2774-d6ebaa2cd8e-refs/pull/4731/head\n",
      "Model Optimizer version: \t    unknown version\n",
      "[ WARNING ] Model Optimizer and Inference Engine versions do no match.\n",
      "[ WARNING ] Consider building the Inference Engine Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino\" (may be incompatible with the current Model Optimizer version)\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2021-08-27 08:37:39.031302: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \n",
      "2021-08-27 08:37:39.031351: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-27 08:37:42.698858: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \n",
      "2021-08-27 08:37:42.698899: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-27 08:37:42.698930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-evenwei): /proc/driver/nvidia/version does not exist\n",
      "2021-08-27 08:37:42.699235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-27 08:37:42.714825: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
      "2021-08-27 08:37:42.715195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f2a7b801f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-27 08:37:42.715235: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-08-27 08:37:51.652362: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-08-27 08:37:51.666428: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-08-27 08:37:51.899646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
      "2021-08-27 08:37:51.899704: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 1201 nodes (878), 1216 edges (893), time = 96.3ms.\n",
      "2021-08-27 08:37:51.899721: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.626ms.\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/jovyan/resnet_chest/saved_model.xml\n",
      "[ SUCCESS ] BIN file: /home/jovyan/resnet_chest/saved_model.bin\n",
      "[ SUCCESS ] Total execution time: 47.98 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1698 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2021_bu_IOTG_OpenVINO-2021-3&content=upg_all&medium=organic or on the GitHub*\n"
     ]
    }
   ],
   "source": [
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    ! $mo_command\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc002839",
   "metadata": {},
   "source": [
    "## 4. Verify Optimized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede744a",
   "metadata": {},
   "source": [
    "#### Load Original Model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3868e13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9978103 , 0.00218971]], dtype=float32), 2.524897336959839)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h5 = tf.keras.models.load_model(f'data_and_models/models/{model_name}.h5')\n",
    "\n",
    "def infer_h5(image_path):\n",
    "    image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, (224, 224)) / 255\n",
    "    X = np.expand_dims(resized_image, axis=0)\n",
    "    start_time = time.time()\n",
    "    result = model_h5.predict(X)\n",
    "    t = time.time() - start_time\n",
    "    return result, t\n",
    "\n",
    "# warm up\n",
    "infer_h5('data_and_models/data/chest/Chest_COVID/ryct.2020003.fig2-a.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f677b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecda10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(f'{model_name}/saved_model.xml', f'{model_name}/saved_model.bin')\n",
    "exec_net = ie.load_network(net, \"CPU\")\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_key = list(exec_net.outputs.keys())[0]\n",
    "network_input_shape = exec_net.input_info[input_key].tensor_desc.dims\n",
    "\n",
    "def infer_ir(image_path):\n",
    "    image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, (224, 224)) / 255\n",
    "    input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)\n",
    "    start_time = time.time()\n",
    "    result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "    t = time.time() - start_time\n",
    "    return result, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695d69c",
   "metadata": {},
   "source": [
    "#### Define Method for Comparing Orginal and Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ebf7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_model(image_path):\n",
    "    result_h5, time_h5 = infer_h5(image_path)\n",
    "    result_ir, time_ir = infer_ir(image_path)\n",
    "    \n",
    "    print('Result:')\n",
    "    print('Keras H5:\\t', result_ir[0])\n",
    "    print('OpenVINO:\\t', result_h5[0])\n",
    "\n",
    "    print('Time:')\n",
    "    print(f'Keras H5:\\t {time_ir:.3f} sec')\n",
    "    print(f'OpenVINO:\\t {time_h5:.3f} sec')\n",
    "    \n",
    "    print(f'Speedup:\\t x{time_h5/time_ir:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffe18c",
   "metadata": {},
   "source": [
    "#### COVID-19 Positive Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c54eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Keras H5:\t [0.99780995 0.00219002]\n",
      "OpenVINO:\t [0.9978103  0.00218971]\n",
      "Time:\n",
      "Keras H5:\t 0.194 sec\n",
      "OpenVINO:\t 0.380 sec\n",
      "Speedup:\t x1.957\n"
     ]
    }
   ],
   "source": [
    "image_path = 'data_and_models/data/chest/Chest_COVID/ryct.2020003.fig2-a.png'\n",
    "comp_model(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eae258",
   "metadata": {},
   "source": [
    "#### COVID-19 Negative Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5faa7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Keras H5:\t [0.07287621 0.92712384]\n",
      "OpenVINO:\t [0.07289597 0.92710406]\n",
      "Time:\n",
      "Keras H5:\t 0.184 sec\n",
      "OpenVINO:\t 0.362 sec\n",
      "Speedup:\t x1.970\n"
     ]
    }
   ],
   "source": [
    "image_path = 'data_and_models/data/chest/Chest_NonCOVID/0a4d9634-7ee8-4512-ba83-6ff5e352b2c2.jpg'\n",
    "comp_model(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9c6d1",
   "metadata": {},
   "source": [
    "## 5. Copy to PHFS for Deployment\n",
    "\n",
    "To deploy the optimized models, we need to put it in PHFS first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d505795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phfs_dir = f'/phfs/openvino/{model_name}'\n",
    "if not os.path.exists(phfs_dir):\n",
    "    os.makedirs(phfs_dir)\n",
    "\n",
    "xml_file = f'{model_name}/saved_model.xml'\n",
    "bin_file = f'{model_name}/saved_model.bin'\n",
    "!cp $xml_file $phfs_dir\n",
    "!cp $bin_file $phfs_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0a8c7",
   "metadata": {},
   "source": [
    "## Appendix: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf7c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering COVID images:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [01:22<00:00,  5.82it/s]\n",
      "  0%|          | 1/505 [00:00<01:32,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Non-COVID images:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [01:18<00:00,  6.48it/s]\n"
     ]
    }
   ],
   "source": [
    "covid_files = glob('data_and_models/data/chest/Chest_COVID/*')\n",
    "noncovid_files = glob('data_and_models/data/chest/Chest_NonCOVID/*')\n",
    "\n",
    "print('Infering COVID images:')\n",
    "covid_pred = [infer_ir(f)[0] for f in tqdm(covid_files, position=0, leave=True)]\n",
    "print('Infering Non-COVID images:')\n",
    "noncovid_pred = [infer_ir(f)[0] for f in tqdm(noncovid_files, position=0, leave=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3a526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       435\n",
      "           1       0.90      0.69      0.78       505\n",
      "\n",
      "    accuracy                           0.79       940\n",
      "   macro avg       0.81      0.80      0.79       940\n",
      "weighted avg       0.82      0.79      0.79       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid_pred_bin = [np.argmax(x) for x in covid_pred]\n",
    "noncovid_pred_bin = [np.argmax(x) for x in noncovid_pred]\n",
    "\n",
    "y_pred_bin = covid_pred_bin\n",
    "y_pred_bin.extend(noncovid_pred_bin)\n",
    "y_test_bin = [0] * len(covid_files)\n",
    "y_test_bin.extend([1] * len(noncovid_files))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
